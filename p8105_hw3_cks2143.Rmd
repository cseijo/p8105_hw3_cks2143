---
title: "Homework 3"
author: Chariz Seijo
output: github_document
---

Solution to HW 3. 

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
```

## Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the levels of items in orders by user. There are user/order variables, such as user ID, order ID, order day, and order hour. There are also item variables, including name, aisle, department, and some numeric codes.

**How many aisles, and which are most items from?**

```{r insta_aisles}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

**Make a plot!**

```{r insta_plot}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

**Make a table!**

```{r insta_table}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>%
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

**Apples vs. ice cream!**

```{r apples_table}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable()
```


## Problem 2

**Load, tidy, and wrangle the accelerometer data.**

```{r accel_df}
accel_df = 
  read_csv(
      "./data/accel_data.csv") %>%
  pivot_longer(
    activity.1:activity.1440,
    names_to = "minute",
    names_prefix = "activity.",
    values_to = "activity_counts"
  ) %>% 
  mutate(
    day = factor(day, 
                 levels=c("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday")),
    minute = as.numeric(minute),
    weekday = 
      ifelse(day %in% c("Saturday", "Sunday"), FALSE, TRUE)
  ) %>% 
  arrange(day)
```

This dataset includes five weeks of accelerometer data collected on a 63 year-old male who was diagnosed with congestive heart failure. It contains `r nrow(accel_df)` observations and `r ncol(accel_df)` variables. Variables in this dataset include week of observation, each day of observation, day of the week, minute of the day, activity counts, and whether each observation happened on a weekday or weekend. 

**Total activity by day**

```{r accel_table}
accel_df %>% 
  group_by(week, day) %>% 
  summarize(total_activity = sum(activity_counts)) %>%
  knitr::kable()
```

This man appears to have noticeable dips in activity on the last two Saturdays of observation. Activity counts also seem to be steady throughout the week and fluctuate more often at the end of the week.

**Plot of total activity by day**

```{r accel_plot}
accel_df %>% 
 ggplot(aes(x = minute, y = activity_counts)) +
  geom_line(aes(color = day), alpha = .5)
```

Based on this graph, we can conclude that there is noticeably less activity during the night, and more activity during the day, with more spikes recorded in the morning/evening.

## Problem 3

```{r}
data("ny_noaa")
```

In the NY NOAA dataset, there are `r ncol(ny_noaa)` columns and `r nrow(ny_noaa)` rows. This dataset includes weather data from New York state weather stations, with the variables weather station ID, date of observation, precipitation measured in tenths of mm, snowfall and snow depth in mm, and maximum and minimum temperature in tenths of degrees C. 

```{r, include=FALSE}
colSums(is.na(ny_noaa))
```

There are a total of 145,838 missing values in the precipitation variable, 381,221 in snowfall, 591,786 in snow depth, 1,134,358 in maximum temperature, and 1,134,420 in minimum temperature.

**Cleaning the data.**

```{r}
noaa_df =
  ny_noaa %>%
  separate(date, c("year", "month", "day")) %>%
  mutate(
    year = as.numeric(year),
    month = as.numeric(month),
    day = as.numeric(day),
    prcp = as.numeric(prcp)*0.1,
    tmax = as.numeric(tmax)*0.1,
    tmin = as.numeric(tmin)*0.1
  )
```

For snow, the most commonly observed value is 0 at `r noaa_df %>% filter (snow == 0) %>% count()` observations. Given that snow does not fall the majority of the year, it would make sense that this is the most commonly observed value.


2-panel plot (org data first - group by station, year, month + summarize; filter january and july; then plot)

2-panel plot (make each plot, then figure out how to merge; first plot - contour plot or bin plot; second plot - filter first, box plot or ridge plot)